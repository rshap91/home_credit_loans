{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "import time\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
    "from sklearn.decomposition import PCA, NMF, TruncatedSVD\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "today = dt.date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PK = 'sk_id_curr'\n",
    "TARGET = 'target'\n",
    "N_CV = 3\n",
    "N_COMPONENTS = 150\n",
    "SEED = 1111\n",
    "DATA_DIR = 'clean_data/'\n",
    "\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, 'mrgd_train.csv')\n",
    "TEST_FILE = os.path.join(DATA_DIR, 'mrgd_test.csv')\n",
    "SUBMISSION_OUTPUT_FILE = os.path.join(DATA_DIR, 'submission_out.csv')\n",
    "\n",
    "DTYPES = {'sk_id_curr':str, 'sk_id_bureau':str, 'sk_id_prev':str,'num_instalment_version':str}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda:\n",
    "    - Load Data\n",
    "    - Create 150 features from PCA, SVD\n",
    "    - Fit Kmeans Cluster Labels\n",
    "    - Fit Naive Bayes Model to data and use predictions as ftrs\n",
    "    - Save all datasets\n",
    "        - Going to model each individually\n",
    "        - Then together\n",
    "        - Then run through feature seleciton...\n",
    "        - Then, if time, polynomial features the resulting selected features and then trim those\n",
    " \n",
    " Will see how compute intensive this ends up being and scale back accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((307511, 527), (48744, 526))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(TRAIN_FILE, dtype=DTYPES)\n",
    "test = pd.read_csv(TEST_FILE, dtype=DTYPES)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sk_id_curr</th>\n",
       "      <th>flag_own_car</th>\n",
       "      <th>flag_own_realty</th>\n",
       "      <th>name_contract_type</th>\n",
       "      <th>flag_cont_mobile</th>\n",
       "      <th>flag_document_10</th>\n",
       "      <th>flag_document_11</th>\n",
       "      <th>flag_document_12</th>\n",
       "      <th>flag_document_13</th>\n",
       "      <th>flag_document_14</th>\n",
       "      <th>...</th>\n",
       "      <th>sk_dpd_pos</th>\n",
       "      <th>name_contract_status_Active</th>\n",
       "      <th>name_contract_status_Amortized debt</th>\n",
       "      <th>name_contract_status_Approved_pos</th>\n",
       "      <th>name_contract_status_Canceled_pos</th>\n",
       "      <th>name_contract_status_Completed_pos</th>\n",
       "      <th>name_contract_status_Demand_pos</th>\n",
       "      <th>name_contract_status_Returned to the store</th>\n",
       "      <th>name_contract_status_Signed_pos</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 527 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sk_id_curr  flag_own_car  flag_own_realty  name_contract_type  \\\n",
       "0     100002             0                1                   0   \n",
       "1     100003             0                0                   0   \n",
       "2     100004             1                1                   1   \n",
       "3     100006             0                1                   0   \n",
       "4     100007             0                1                   0   \n",
       "\n",
       "   flag_cont_mobile  flag_document_10  flag_document_11  flag_document_12  \\\n",
       "0                 1                 0                 0                 0   \n",
       "1                 1                 0                 0                 0   \n",
       "2                 1                 0                 0                 0   \n",
       "3                 1                 0                 0                 0   \n",
       "4                 1                 0                 0                 0   \n",
       "\n",
       "   flag_document_13  flag_document_14   ...    sk_dpd_pos  \\\n",
       "0                 0                 0   ...           0.0   \n",
       "1                 0                 0   ...           0.0   \n",
       "2                 0                 0   ...           0.0   \n",
       "3                 0                 0   ...           0.0   \n",
       "4                 0                 0   ...           0.0   \n",
       "\n",
       "   name_contract_status_Active  name_contract_status_Amortized debt  \\\n",
       "0                         19.0                                  0.0   \n",
       "1                         26.0                                  0.0   \n",
       "2                          3.0                                  0.0   \n",
       "3                         18.0                                  0.0   \n",
       "4                         62.0                                  0.0   \n",
       "\n",
       "   name_contract_status_Approved_pos  name_contract_status_Canceled_pos  \\\n",
       "0                                0.0                                0.0   \n",
       "1                                0.0                                0.0   \n",
       "2                                0.0                                0.0   \n",
       "3                                0.0                                0.0   \n",
       "4                                0.0                                0.0   \n",
       "\n",
       "   name_contract_status_Completed_pos  name_contract_status_Demand_pos  \\\n",
       "0                                 0.0                              0.0   \n",
       "1                                 2.0                              0.0   \n",
       "2                                 1.0                              0.0   \n",
       "3                                 2.0                              0.0   \n",
       "4                                 3.0                              0.0   \n",
       "\n",
       "   name_contract_status_Returned to the store  \\\n",
       "0                                         0.0   \n",
       "1                                         0.0   \n",
       "2                                         0.0   \n",
       "3                                         1.0   \n",
       "4                                         0.0   \n",
       "\n",
       "   name_contract_status_Signed_pos  target  \n",
       "0                              0.0       1  \n",
       "1                              0.0       0  \n",
       "2                              0.0       0  \n",
       "3                              0.0       0  \n",
       "4                              1.0       0  \n",
       "\n",
       "[5 rows x 527 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 525),(48744, 525)\n"
     ]
    }
   ],
   "source": [
    "# Target var\n",
    "y_train = train[TARGET].values\n",
    "# sk ids\n",
    "train_id = train[PK]\n",
    "test_id = test[PK]\n",
    "\n",
    "train.drop([PK, TARGET], axis=1, inplace=True)\n",
    "test.drop(PK, axis=1, inplace=True)\n",
    "print(\"{},{}\".format(train.shape, test.shape))\n",
    "\n",
    "x_train = train.values\n",
    "x_test = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns[test.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rscaler = RobustScaler()\n",
    "rscaler.fit(x_train)\n",
    "\n",
    "x_train_scaled = rscaler.transform(x_train)\n",
    "x_test_scaled = rscaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((307511, 150), (48744, 150))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA\n",
    "pca = PCA(N_COMPONENTS, random_state=SEED)\n",
    "pca.fit(x_train_scaled)\n",
    "\n",
    "pca_train = pca.transform(x_train_scaled)\n",
    "pca_test = pca.transform(x_test_scaled)\n",
    "pca_train.shape, pca_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((307511, 150), (48744, 150))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVD \n",
    "svd = TruncatedSVD(N_COMPONENTS, random_state=SEED)\n",
    "svd.fit(x_train_scaled)\n",
    "\n",
    "svd_train = svd.transform(x_train_scaled)\n",
    "svd_test = svd.transform(x_test_scaled)\n",
    "svd_train.shape, svd_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init 1/10 with method: k-means++\n",
      "Inertia for init 1/10: 4826323782041.433594\n",
      "Init 2/10 with method: k-means++\n",
      "Inertia for init 2/10: 2771735050209.527832\n",
      "Init 3/10 with method: k-means++\n",
      "Inertia for init 3/10: 15680082162777.380859\n",
      "Init 4/10 with method: k-means++\n",
      "Inertia for init 4/10: 8744329059667.680664\n",
      "Init 5/10 with method: k-means++\n",
      "Inertia for init 5/10: 8752714647388.677734\n",
      "Init 6/10 with method: k-means++\n",
      "Inertia for init 6/10: 25887559984659.769531\n",
      "Init 7/10 with method: k-means++\n",
      "Inertia for init 7/10: 8573167688360.576172\n",
      "Init 8/10 with method: k-means++\n",
      "Inertia for init 8/10: 8813832329565.552734\n",
      "Init 9/10 with method: k-means++\n",
      "Inertia for init 9/10: 9672471325251.113281\n",
      "Init 10/10 with method: k-means++\n",
      "Inertia for init 10/10: 21611240491127.824219\n",
      "Minibatch iteration 1/12400: mean batch inertia: 9840724.404085, ewa inertia: 9840724.404085 \n",
      "Minibatch iteration 2/12400: mean batch inertia: 75320656.934944, ewa inertia: 10905397.205973 \n",
      "Minibatch iteration 3/12400: mean batch inertia: 3577528439.676502, ewa inertia: 68897004.728127 \n",
      "Minibatch iteration 4/12400: mean batch inertia: 20256608.520290, ewa inertia: 68106134.839995 \n",
      "Minibatch iteration 5/12400: mean batch inertia: 736009666.559464, ewa inertia: 78965931.071028 \n",
      "Minibatch iteration 6/12400: mean batch inertia: 13912020.543968, ewa inertia: 77908185.185875 \n",
      "Minibatch iteration 7/12400: mean batch inertia: 8690937.991186, ewa inertia: 76782745.411253 \n",
      "Minibatch iteration 8/12400: mean batch inertia: 15148547.122494, ewa inertia: 75780602.433275 \n",
      "Minibatch iteration 9/12400: mean batch inertia: 51369729.232428, ewa inertia: 75383693.154925 \n",
      "[MiniBatchKMeans] Reassigning 48 cluster centers.\n",
      "Minibatch iteration 10/12400: mean batch inertia: 40585633.382576, ewa inertia: 74817893.124806 \n",
      "Minibatch iteration 11/12400: mean batch inertia: 2447985424.504781, ewa inertia: 113404477.248027 \n",
      "Converged (lack of improvement in inertia) at iteration 11/12400\n",
      "Computing label assignment and total inertia\n"
     ]
    }
   ],
   "source": [
    "# Iterated through various n_clusters and batch_size\n",
    "# best auc is n_clusters = 60 batch_size=2500 with auc of 0.0.558\n",
    "nclust = 60\n",
    "bsize = 2500\n",
    "\n",
    "mbkm = MiniBatchKMeans(nclust, batch_size=bsize, verbose=1, n_init=10, random_state=SEED)\n",
    "km_train = mbkm.fit_transform(x_train_scaled)\n",
    "km_test = mbkm.transform(x_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525, (307511, 525))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bern_cols = train.columns[train.apply(lambda col: col.nunique() == 2)].tolist()\n",
    "# mult_cols = train.columns[(train.dtypes==int) & ~train.columns.isin(bern_cols)].tolist()\n",
    "# gaus_cols = train.columns[~train.columns.isin(bern_cols+mult_cols)]\n",
    "# len(bern_cols) + len(mult_cols) + len(gaus_cols), train.shape\n",
    "\n",
    "# bern_locs = [train.columns.get_loc(b) for b in bern_cols]\n",
    "# mult_locs = [train.columns.get_loc(m) for m in mult_cols]\n",
    "# gaus_locs = [train.columns.get_loc(g) for g in gaus_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayesClf():\n",
    "    \"\"\"\n",
    "    Uses Bernoulli NB for Binary Features,\n",
    "    Multinomial NB for integer ftrs,\n",
    "    Gaussian NB for all other ftrs.\n",
    "    \n",
    "    Final Probs is average of 3 predicted probabilities of above models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, bparams={}, mparams={}, gparams={}):\n",
    "        self.bnb = BernoulliNB(**bparams)\n",
    "        self.mnb = MultinomialNB(**mparams)\n",
    "        self.gnb = GaussianNB(**gparams)\n",
    "        \n",
    "        \n",
    "    def get_cols(self, data):\n",
    "        bern_cols = data.columns[data.apply(lambda col: col.nunique() == 2)].tolist()\n",
    "        mult_cols = data.columns[(data.dtypes==int) & ~data.columns.isin(bern_cols)].tolist()\n",
    "        gaus_cols = data.columns[~data.columns.isin(bern_cols+mult_cols)]\n",
    "        assert len(bern_cols) + len(mult_cols) + len(gaus_cols) == data.shape[1]\n",
    "        \n",
    "        self.bern_locs = [data.columns.get_loc(b) for b in bern_cols]\n",
    "        self.mult_locs = [data.columns.get_loc(m) for m in mult_cols]\n",
    "        self.gaus_locs = [data.columns.get_loc(g) for g in gaus_cols]\n",
    "        \n",
    "    \n",
    "    def fit(self, data, target):\n",
    "        self.get_cols(data)\n",
    "        self.bnb.fit(data.values[:,self.bern_locs], target)\n",
    "        self.mnb.fit(data.values[:,self.mult_locs], target)\n",
    "        self.gnb.fit(data.values[:,self.gaus_locs], target)\n",
    "\n",
    "    \n",
    "    def predict(self, new_data):\n",
    "        bprobs = self.bnb.predict_proba(new_data[:,self.bern_locs])[:,1]\n",
    "        mprobs = self.mnb.predict_proba(new_data[:,self.mult_locs])[:,1]\n",
    "        gprobs = self.gnb.predict_proba(new_data[:,self.gaus_locs])[:,1]\n",
    "        all_probs = np.vstack((bprobs, mprobs, gprobs))\n",
    "        final_probs = all_probs.mean(0)\n",
    "\n",
    "        return final_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "(307511,) (307511,) (307511,)\n",
      "0.591584954654\n",
      "0.2\n",
      "(307511,) (307511,) (307511,)\n",
      "0.598932452455\n",
      "0.3\n",
      "(307511,) (307511,) (307511,)\n",
      "0.603396315046\n",
      "0.4\n",
      "(307511,) (307511,) (307511,)\n",
      "0.606131171884\n",
      "0.5\n",
      "(307511,) (307511,) (307511,)\n",
      "0.607403046501\n",
      "0.6\n",
      "(307511,) (307511,) (307511,)\n",
      "0.60724274623\n",
      "0.7\n",
      "(307511,) (307511,) (307511,)\n",
      "0.605229087143\n",
      "0.8\n",
      "(307511,) (307511,) (307511,)\n",
      "0.600183778401\n",
      "0.9\n",
      "(307511,) (307511,) (307511,)\n",
      "0.590787096525\n"
     ]
    }
   ],
   "source": [
    "# you should cross validate\n",
    "for p in np.arange(0.1, 1, 0.1):\n",
    "    print(p)\n",
    "    priors = (p, 1-p)\n",
    "    nbc = NaiveBayesClf({'class_prior':priors}, {'class_prior':priors}, {'priors':priors})\n",
    "    nbc.fit(train, y_train)\n",
    "    probs = nbc.predict(x_train)\n",
    "    print(metrics.roc_auc_score(y_train, probs))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_prior = (0.5, 0.5)\n",
    "nbc = NaiveBayesClf({'class_prior':nb_prior}, {'class_prior':nb_prior}, {'priors':nb_prior})\n",
    "nbc.fit(train, y_train)\n",
    "\n",
    "nb_train_probs = nbc.predict(x_train)\n",
    "nb_test_probs = nbc.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine All New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 150) (48744, 150) (307511, 150) (48744, 150) (307511, 60) (48744, 60) (307511,) (48744,)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    pca_train.shape,\n",
    "    pca_test.shape,\n",
    "    svd_train.shape,\n",
    "    svd_test.shape,\n",
    "    km_train.shape,\n",
    "    km_test.shape,\n",
    "    nb_train_probs.shape,\n",
    "    nb_test_probs.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((307511, 361), (48744, 361))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_train_df = pd.DataFrame(pca_train, columns = ['pca_ftr_'+str(n) for n in range(pca_train.shape[1])])\n",
    "pca_test_df = pd.DataFrame(pca_test, columns = ['pca_ftr_'+str(n) for n in range(pca_test.shape[1])])\n",
    "\n",
    "svd_train_df = pd.DataFrame(svd_train, columns = ['svd_ftr_'+str(n) for n in range(svd_train.shape[1])])\n",
    "svd_test_df = pd.DataFrame(svd_test, columns = ['svd_ftr_'+str(n) for n in range(svd_test.shape[1])])\n",
    "\n",
    "km_train_df = pd.DataFrame(km_train, columns = ['km_ftr_'+str(n) for n in range(km_train.shape[1])])\n",
    "km_test_df = pd.DataFrame(km_test, columns = ['km_ftr_'+str(n) for n in range(km_test.shape[1])])\n",
    "\n",
    "nb_train_df = pd.Series(nb_train_probs, name='nb_probs')\n",
    "nb_test_df = pd.Series(nb_test_probs, name='nb_probs')\n",
    "\n",
    "eng_ftrs_train = pd.concat([pca_train_df, svd_train_df, km_train_df, nb_train_df], axis=1)\n",
    "eng_ftrs_test = pd.concat([pca_test_df, svd_test_df, km_test_df, nb_test_df], axis=1)\n",
    "\n",
    "eng_ftrs_train.shape, eng_ftrs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng_ftrs_train.to_csv('clean_data/eng_ftrs_train.csv',index=False)\n",
    "eng_ftrs_test.to_csv('clean_data/eng_ftrs_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
