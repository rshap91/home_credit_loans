{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "import time\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "\n",
    "# https://stackoverflow.com/questions/14254203/mixing-categorial-and-continuous-data-in-naive-bayes-classifier-using-scikit-lea?rq=1\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "today = dt.date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# should've done this in cleaning\n",
    "# rscaler = RobustScaler()\n",
    "# rscaler.fit(x_train)\n",
    "\n",
    "# x_train_scaled = rscaler.transform(x_train)\n",
    "# x_test_scaled = rscaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook is going to be used a few times to get parameters for models and test out different configurations or sets of features. \n",
    "\n",
    "The first time through I tried out a bunch of different algorthims (mainly tree algorithms) and parameters.\n",
    "I attempted to grid-search parameters, but doing so was to resource intensive and would take days to finish even for only a modest parameter search space. I ended up running bayesian optimizations on the model parameters and found that LightGBM was the best combination of fast and high auc (approximately the same as xgboost and a fraction of the time).\n",
    "\n",
    "For further explorations and iterations I stuck with LGBM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PK = 'sk_id_curr'\n",
    "TARGET = 'target'\n",
    "N_CV = 4\n",
    "SEED = 1111\n",
    "DATA_DIR = 'clean_data/'\n",
    "\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, 'mrgd_train.csv')\n",
    "TEST_FILE = os.path.join(DATA_DIR, 'mrgd_test.csv')\n",
    "SUBMISSION_OUTPUT_FILE = os.path.join(DATA_DIR, 'submission_out.csv')\n",
    "\n",
    "DTYPES = {'sk_id_curr':str, 'sk_id_bureau':str, 'sk_id_prev':str,'num_instalment_version':str}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(TRAIN_FILE, dtype=DTYPES)\n",
    "test = pd.read_csv(TEST_FILE, dtype=DTYPES)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate keys, target, train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Target var\n",
    "y_train = train[TARGET].values\n",
    "pd.value_counts(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sk ids\n",
    "train_id = train[PK]\n",
    "test_id = test[PK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop([PK, TARGET], axis=1, inplace=True)\n",
    "test.drop(PK, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{},{}\".format(train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make arrays\n",
    "x_train = train[features].values\n",
    "x_test = test[features].values\n",
    "###\n",
    "x_train = train.values\n",
    "x_test = test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "et_default_params = {\n",
    "    'n_jobs': -1,\n",
    "    'verbose' : 1\n",
    "}\n",
    "\n",
    "rf_default_params = {\n",
    "    'n_jobs': -1,\n",
    "    'verbose' : 1\n",
    "}\n",
    "\n",
    "gb_default_params = {\n",
    "    'verbose' : 1\n",
    "}\n",
    "\n",
    "xgb_default_params = {\n",
    "    'silent': 0,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc'\n",
    "}\n",
    "\n",
    "lgb_default_params = {\n",
    "    'silent': 0,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    #'is_unbalanced':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "et_params = {\n",
    "    'n_estimators': list(range(25,201, 25)),\n",
    "    'max_features': [0.01, 0.05, 0.1, 0.3, 0.5, 0.75],\n",
    "    'max_depth': list(range(5,26, 5)),\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': list(range(25,201, 25)),\n",
    "    'max_features': [0.01, 0.1, 0.5, 0.8],\n",
    "    'max_depth': list(range(5,26, 5)),\n",
    "}\n",
    "\n",
    "\n",
    "gb_params = {\n",
    "    'n_estimators': range(20, 101, 20),\n",
    "    'learning_rate': [0.01, 0.1, 0.5, 0.8],\n",
    "    'max_features': [0.01, 0.1, 0.5, 0.8],\n",
    "    'max_depth': list(range(5,26, 5)),\n",
    "}\n",
    "\n",
    "\n",
    "xgb_params = {\n",
    "    'colsample_bytree': [0.01, 0.1, 0.5, 0.8],\n",
    "    'subsample': [0.01, 0.1, 0.5, 0.8],\n",
    "    'learning_rate': [0.01, 0.1, 0.5, 0.8],\n",
    "    'max_depth': list(range(5,26, 5)),\n",
    "    'scale_pos_weight': range(2, int(pd.value_counts(y_train)[0]/pd.value_counts(y_train)[1])*2, 4),\n",
    "    'nrounds': [2**n for n in range(5,9)]\n",
    "}\n",
    "\n",
    "lgb_params = {\n",
    "    'boosting': ['gbdt', 'dart'],\n",
    "    'num_iterations': [2**n for n in range(5,10)],\n",
    "    'learning_rate': [0.01, 0.1, 0.5, 0.8],\n",
    "    'max_depth': list(range(5,26, 5)),\n",
    "    'scale_pos_weight': range(2, int(pd.value_counts(y_train)[0]/pd.value_counts(y_train)[1])*2, 4),\n",
    "    'subsample': [0.01, 0.1, 0.5, 0.8],\n",
    "    'colsample_bytree': [0.01, 0.1, 0.5, 0.8],\n",
    "}\n",
    "\n",
    "# potential other params afterwords\n",
    "# 'lambda_l1': [0, 0.6,]\n",
    "# 'lambda_l2': [0, 0.6,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.prod(list(map(len, xgb_params.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OVERSAMPLE\n",
    "def get_weights(ser):\n",
    "    vcs = ser.value_counts()\n",
    "    class_labels = vcs.index.tolist()\n",
    "    class_sizes = vcs.values\n",
    "    nclasses = len(class_labels)\n",
    "    class_weights = dict(zip(class_labels,(nclasses**-1/class_sizes)))\n",
    "    return class_weights\n",
    "\n",
    "def oversample(ser, size):\n",
    "    p = ser.map(get_weights(ser))\n",
    "    samp = np.random.choice(ser.index,size,p = p)\n",
    "    return samp\n",
    "\n",
    "\n",
    "def grid_search_params(algo, default_params, grid_params, cv=N_CV, \n",
    "                       x_train=x_train, y_train=y_train):\n",
    "    est = algo(**default_params)\n",
    "    grid = GridSearchCV(est, grid_params, scoring='roc_auc', cv=cv, n_jobs=-1, )\n",
    "    print('Grid Searching Params')\n",
    "    \n",
    "    start = time.time()\n",
    "    grid.fit(x_train, y_train)\n",
    "    print('Fitting Completed in {} minutes'.format((time.time()-start)/60))\n",
    "    print('Best Score', grid.best_score_)\n",
    "    \n",
    "    return grid.best_estimator, grid.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# results={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# names = ['et', 'rf', 'gb', 'xgb', 'lgb']\n",
    "# algos = [ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier, XGBClassifier, LGBMClassifier]\n",
    "# default_params = [et_default_params, rf_default_params, gb_default_params, xgb_default_params, lgb_default_params]\n",
    "# param_grids = [et_params, rf_params, gb_params, xgb_params, lgb_params]\n",
    "\n",
    "\n",
    "# for name, algo, dparams, gparams in zip(algos,default_params,param_grids):\n",
    "#     best_estimator, best_params = grid_search_params(algo, dparams, gparams)\n",
    "#     results[name] = (best_estimator, best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Bayesian Param Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New to this - exploring using bayes_opt python package for finding optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rf_func(**params):\n",
    "    params['n_estimators'] = int(np.round(params['n_estimators']))\n",
    "    params['max_depth'] = int(np.round(params['max_depth']))\n",
    "    \n",
    "    \n",
    "    est = RandomForestClassifier(**rf_default_params, **params)\n",
    "    cv = StratifiedKFold(N_CV, True, SEED)\n",
    "    roc_auc = np.mean(cross_val_score(est, x_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1))\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{p: (min(rf_params[p]), max(rf_params[p])) for p in rf_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "rfBO = BayesianOptimization(rf_func, {p: (min(rf_params[p]), max(rf_params[p])) for p in rf_params})\n",
    "rfBO.maximize(10, 100)\n",
    "print('TIME TAKEN (MIN):', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = rfBO.res['max']\n",
    "# best_params = result['max_params']\n",
    "# best_score = result['max_value']\n",
    "print(result)\n",
    "all_results['rf'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def et_func(**params):\n",
    "    params['n_estimators'] = int(np.round(params['n_estimators']))\n",
    "    params['max_depth'] = int(np.round(params['max_depth']))\n",
    "    \n",
    "    cv = StratifiedKFold(N_CV, True, SEED)\n",
    "    est = RandomForestClassifier(**et_default_params, **params)\n",
    "    roc_auc = np.mean(cross_val_score(est, x_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1))\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "etBO = BayesianOptimization(et_func, {p: (min(et_params[p]), max(et_params[p])) for p in et_params})\n",
    "etBO.maximize(10, 100)\n",
    "print('TIME TAKEN (MIN):', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = etBO.res['max']\n",
    "# best_params = result['max_params']\n",
    "# best_score = result['max_value']\n",
    "print(result)\n",
    "all_results['et'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgbm_bounds = {p: (min(lgb_params[p]), max(lgb_params[p])) for p in lgb_params}\n",
    "lgbm_bounds.update({'boosting': (0,1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lgb_func(**params):\n",
    "    params['boosting'] = 'gbdt' if np.round(params['boosting']) == 0 else 'dart'\n",
    "    params['num_iterations'] = int(np.round(params['num_iterations']))\n",
    "    params['max_depth'] = int(np.round(params['max_depth']))\n",
    "    params['learning_rate'] = np.clip(params['learning_rate'], 0.0001, 1)\n",
    "    params['subsample'] = np.clip(params['subsample'], 0.0001, 1)\n",
    "    params['colsample_bytree'] = np.clip(params['colsample_bytree'], 0.0001, 1)    \n",
    "    \n",
    "    cv = StratifiedKFold(N_CV, True, SEED)\n",
    "    est = LGBMClassifier(**lgb_default_params, **params)\n",
    "    roc_auc = np.mean(cross_val_score(est, x_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1))\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "lgbBO = BayesianOptimization(lgb_func, lgbm_bounds)\n",
    "lgbBO.maximize(10, 100)\n",
    "print('TIME TAKEN (MIN):', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = lgbBO.res['max']\n",
    "# best_params = result['max_params']\n",
    "# best_score = result['max_value']\n",
    "print(result)\n",
    "all_results['lgb'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgb_func(**params):\n",
    "    params['nrounds'] = int(np.round(params['nrounds']))\n",
    "    params['max_depth'] = int(np.round(params['max_depth']))\n",
    "    params['learning_rate'] = np.clip(params['learning_rate'], 0.0001, 1)\n",
    "    params['subsample'] = np.clip(params['subsample'], 0.0001, 1)\n",
    "    params['colsample_bytree'] = np.clip(params['colsample_bytree'], 0.0001, 1)    \n",
    "    \n",
    "    cv = StratifiedKFold(N_CV, True, SEED)\n",
    "    est = XGBClassifier(**xgb_default_params, **params)\n",
    "    roc_auc = np.mean(cross_val_score(est, x_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1))\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "xgbBO = BayesianOptimization(xgb_func, {p: (min(xgb_params[p]), max(xgb_params[p])) for p in xgb_params})\n",
    "xgbBO.maximize(10, 100)\n",
    "print('TIME TAKEN (MIN):', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = xgbBO.res['max']\n",
    "# best_params = result['max_params']\n",
    "# best_score = result['max_value']\n",
    "print(result)\n",
    "all_results['xgb'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('extra/bayesian_opt_params.json', 'w') as f:\n",
    "    json.dump(all_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Results and Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('extra/bayesian_opt_params.json', 'r') as f:\n",
    "    all_results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = all_results['lgb']['max_params']\n",
    "params['boosting'] = 'gbdt' if np.round(params['boosting'] == 0) else 'dart'\n",
    "params['max_depth'] = int(np.round(params['max_depth']))\n",
    "params['num_iterations'] = int(np.round(params['num_iterations']))\n",
    "params['scale_pos_weight'] = int(np.round(params['scale_pos_weight']))\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(4, True, SEED)\n",
    "est = LGBMClassifier(**lgb_default_params, **params)\n",
    "roc_auc = np.mean(cross_val_score(est, x_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1))\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore and Add in Engineered Ftrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_ftrs_train = pd.read_csv('clean_data/eng_ftrs_train.csv')\n",
    "eng_ftrs_test = pd.read_csv('clean_data/eng_ftrs_test.csv')\n",
    "eng_ftrs_train.shape, eng_ftrs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_all = pd.concat((train, eng_ftrs_train), axis=1)\n",
    "xtest_all = pd.concat((test, eng_ftrs_test), axis=1)\n",
    "\n",
    "xtrain_all.shape, xtest_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engineered features _alone_ do pretty well\n",
    "cv = StratifiedKFold(N_CV, True, SEED)\n",
    "est = LGBMClassifier(**lgb_default_params, **params)\n",
    "roc_auc = np.mean(cross_val_score(est, eng_ftrs_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1))\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :-/ combined no improvement\n",
    "cv = StratifiedKFold(N_CV, True, SEED)\n",
    "est = LGBMClassifier(**lgb_default_params, **params)\n",
    "roc_auc = np.mean(cross_val_score(est, xtrain_all.values, y_train, scoring='roc_auc', cv=cv, n_jobs=-1))\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Filter to Use only Selected Features From Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_ftrs = pd.read_csv('extra/all_selected_ftrs.csv', names=['ftr', 'score'])\n",
    "selected_ftrs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# don't need all 500 - same performance w 300\n",
    "final_ftrs = selected_ftrs.ftr[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :-( still no improvement\n",
    "cv = StratifiedKFold(N_CV, True, SEED)\n",
    "est = LGBMClassifier(**lgb_default_params, **params)\n",
    "roc_auc = np.mean(cross_val_score(est, xtrain_all[final_ftrs].values, y_train, scoring='roc_auc', cv=cv, n_jobs=-1))\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratch Code for Generating Submission Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = all_results['lgb']['max_params']\n",
    "params['boosting'] = 'gbdt' if np.round(params['boosting'] == 0) else 'dart'\n",
    "params['max_depth'] = int(np.round(params['max_depth']))\n",
    "params['n_iter'] = int(np.round(params['n_iter']))\n",
    "params['scale_pos_weight'] = int(np.round(params['scale_pos_weight']))\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clf = LGBMClassifier(**lgb_default_params, **params)\n",
    "lgb_clf.fit(x_train, y_train)\n",
    "probs = lgb_clf.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame([test_id,probs[:,1]], index=['SK_ID_CURR', 'TARGET']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algo = 'lgbm'\n",
    "submission.to_csv('submissions/{}_{}.csv'.format(algo, today.strftime('%Y%m%d')), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "# nrounds = xgb_params.pop('nrounds', 75)\n",
    "# clf = xgb.train(xgb_params, dtrain, nrounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dtest = xgb.DMatrix(x_test)\n",
    "# preds = clf.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submission['TARGET'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# algo = 'xgboost'\n",
    "# submission.to_csv('submissions/{}_{}.csv'.format(algo, today.strftime('%Y%m%d')), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
